{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLGlobalHealth/StatML4PopHealth/blob/main/practicals/day5/practical7/phylo_lab2_mpxv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/imperial.png\" width=\"250\" vspace=\"8\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/mlgh.png\" width=\"220\" hspace=\"50\" vspace=\"5\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/ammi.png\" width=\"190\"/>\n",
        "\n",
        "<font size=\"6\">Modern Statistics and Machine Learning <br>\n",
        "for Population Health in Africa </font>\n",
        "\n",
        "<font size=\"4\">24th - 28th March 2025</font>\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "Ha_2-q5djsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Phylogenetics: Practical part 2\n",
        "### AIMS-Imperial: Modern Statistics for Global Health\n",
        "**Author**: Dr Alexandra Blenkinsop\n",
        "\n",
        "**Objective**: This practical will demonstrate Bayesian phylogenetic inference using the package phylostan, to date a phylogenetic tree and estimate several parameters such as the evolutionary rate, tree height and effective population size.\n"
      ],
      "metadata": {
        "id": "RLcBSHu3NKEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗Phylostan takes a long time so run so to make things easier we will provide the pregenerated phylostan output. However, if you would like to generate this output yourself, please uncomment the two code chunks below to install the packages required for phylostan.\n",
        "\n",
        "If you decide to install phylostan, when installing setuptools you will be asked to restart your session - please click Restart session button. Note, this will erase the runtime state and local variable, so it is better to do this before running any other cells."
      ],
      "metadata": {
        "id": "vo1jApG1A_m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment this code chunk if you would like to run phylostan\n",
        "\n",
        "# !pip install setuptools==\"68.2.2\""
      ],
      "metadata": {
        "id": "QuvqFeMaBEm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment this code chunk if you would like to run phylostan\n",
        "\n",
        "# !pystan=='2.19.1.1' nest-asyncio\n",
        "# !pip install git+https://github.com/4ment/phylostan.git"
      ],
      "metadata": {
        "id": "tiwoKg8eBGR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment this code chunk if you would like to run phylostan\n",
        "\n",
        "# import pystan\n",
        "\n",
        "# # for phylostan\n",
        "# import subprocess\n",
        "# import shlex\n",
        "\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ykotz-DtBIFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages\n",
        "!pip install biopython ete3 scikit-bio PyQt5 SciencePlots phytreeviz charset_normalizer arviz DendroPy"
      ],
      "metadata": {
        "id": "RmeuUNo0NDl5",
        "outputId": "e44f67a9-1eda-45ae-cdbd-e81714cb36d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting ete3\n",
            "  Downloading ete3-3.1.3.tar.gz (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-bio\n",
            "  Downloading scikit-bio-0.6.3.tar.gz (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieloEmX-LG1k"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from Bio import SeqIO, Phylo\n",
        "from Bio.Align import MultipleSeqAlignment\n",
        "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor, DistanceCalculator\n",
        "from Bio.Phylo.Consensus import *\n",
        "from Bio.Phylo import write as phylo_write, draw\n",
        "from ete3 import Tree, TextFace\n",
        "from ete3 import Tree as EteTree\n",
        "from ete3.treeview.main import TreeStyle, NodeStyle\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skbio import DistanceMatrix\n",
        "from skbio.tree import nj\n",
        "import re\n",
        "from phytreeviz import TreeViz\n",
        "import os\n",
        "import io\n",
        "import arviz as az\n",
        "from collections import defaultdict\n",
        "\n",
        "from Bio.Phylo.Consensus import majority_consensus\n",
        "import dendropy\n",
        "\n",
        "# Aesthetics\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "font = {\"family\": \"sans-serif\",\n",
        "        \"weight\": \"normal\",\n",
        "\t\t\"size\": 10.5}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Adjust this as required - this is where your output will be stored.\n",
        "output_dir = Path(*[\"drive\", \"MyDrive\", \"StatML4PopHealth\", \"practical7\",\"mpxv\"])\n",
        "output_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "dxig6B68P8Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8_4JeeBLG1p"
      },
      "source": [
        "### Data\n",
        "The dataset for this practical lab contains 113 whole genome consensus sequences sampled in Nigeria between 2021-2023 from a study by Parker et al (2024, https://doi.org/10.1101/2024.06.18.24309104) estimating the timing of the emergence of the MPOX virus in humans. The alignment was obtained from NextStrain (https://nextstrain.org/mpox/all-clades), however for the purpose of this practical lab the alignment was subset to include only the sequences from the 2022-2023 oubreak in Nigeria. We will see the implications of this later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu91fUdBLG1q"
      },
      "source": [
        "### Read in the alignment\n",
        "\n",
        "Your first task is to load the multiple sequence alignment and have a look at its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3S_F8WHLG1r"
      },
      "outputs": [],
      "source": [
        "# load the input data\n",
        "!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day5/practical7/data/mpxv_alignment.fasta\"\n",
        "\n",
        "sequences = list(SeqIO.parse(\"mpxv_alignment.fasta\", \"fasta\"))\n",
        "\n",
        "# summarise alignment\n",
        "print(f\"Number of sequences: {len(sequences)}\")\n",
        "\n",
        "shortest_seq = min(sequences, key=lambda seq: len(seq.seq))\n",
        "longest_seq = max(sequences, key=lambda seq: len(seq.seq))\n",
        "\n",
        "print(f\"- Shortest sequence: {shortest_seq.id} | Length: {len(shortest_seq.seq)}\")\n",
        "print(f\"- Longest sequence: {longest_seq.id} | Length: {len(longest_seq.seq)}\")\n",
        "\n",
        "# print first sequence entry\n",
        "record = sequences[0]\n",
        "print(record)\n",
        "print(\"ID:\", record.id)\n",
        "print(\"Description:\", record.description)\n",
        "print(\"Sequence type:\", type(record.seq))\n",
        "print(\"Sequence data:\", record.seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LfsFbK6LG1t"
      },
      "source": [
        "### Visualizing Sequence Data\n",
        "Let's visualize the alignment, recoding ambiguous bases as 'others'. The x-axis is the position in the alignment, but this is not meaningful unless it is mapped to some known genomic coordinates. The y-axis are the taxa. We show the first 30 taxa only.\n",
        "\n",
        "What do you notice, comparing with the alignment of HIV sequences from the previous lab?\n",
        "\n",
        "A:\n",
        "- The length of the alignment is much longer (almost 200,000 nucleotides)\n",
        "- The sequences look almost identical for the first 1000 positions - there are far fewer mutations than in the HIV alignment. This could be because the mutation rate is slower for MPXV, or because the sampling period covers a shorter time period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ovB201CLG1t"
      },
      "outputs": [],
      "source": [
        "# define mapping for nucleotide bases\n",
        "nucleotide_mapping = {'a': 1, 'c': 2, 'g': 3, 't': 4, '-': 0}\n",
        "reverse_mapping = {v: k for k, v in nucleotide_mapping.items()}  # reverse ordering for legend\n",
        "reverse_mapping[5] = 'Other'  # label for unknown bases\n",
        "\n",
        "# convert sequences to a matrix of nucleotide characters\n",
        "alignment_array = np.array([list(str(seq.seq)) for seq in sequences[:30]])\n",
        "\n",
        "# convert nucleotides to numbers using the mapping\n",
        "alignment_numeric = np.array([\n",
        "    [nucleotide_mapping.get(nt, 5) for nt in str(seq.seq)]  # map unknown bases to 5\n",
        "    for seq in sequences[:30]\n",
        "])\n",
        "\n",
        "# convert to DataFrame\n",
        "alignment_df = pd.DataFrame(alignment_numeric)\n",
        "alignment_df_subset = alignment_df.iloc[:, :1000]\n",
        "\n",
        "# define a discrete colormap\n",
        "colors = [\"black\", \"purple\", \"blue\", \"green\", \"yellow\",\"orange\"]\n",
        "cmap = mcolors.ListedColormap(colors[:len(nucleotide_mapping) + 1])\n",
        "bounds = sorted(list(nucleotide_mapping.values()) + [max(nucleotide_mapping.values()) + 1])\n",
        "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "# plot as a heatmap\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.heatmap(alignment_df_subset, cbar=True, cmap=cmap, norm=norm)\n",
        "\n",
        "# formatting\n",
        "colorbar = ax.collections[0].colorbar\n",
        "tick_positions = np.array(bounds[:-1]) + 0.5\n",
        "colorbar.set_ticks(tick_positions)\n",
        "colorbar.set_ticklabels([reverse_mapping.get(i, \"Other\") for i in bounds[:-1]])\n",
        "\n",
        "# Labels and title\n",
        "plt.title(\"Sequence Alignment (First 30 Sequences)\")\n",
        "plt.xlabel(\"Alignment Position\")\n",
        "plt.ylabel(\"Sequence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLXhzJ5LLG1u"
      },
      "source": [
        "# Pre-process alignment\n",
        "\n",
        "The characters need to be all upper case and with no ambiguous characters to be used with most bioinformatic tools. Clean up the alignment and save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A78S0zZlLG1v"
      },
      "outputs": [],
      "source": [
        "input_file = \"mpxv_alignment.fasta\"\n",
        "output_file = os.path.join(output_dir, \"cleaned_alignment.fasta\")\n",
        "\n",
        "# clean sequences while keeping gaps (\"-\")\n",
        "with open(output_file, \"w\") as out_f:\n",
        "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
        "        cleaned_seq = str(record.seq).upper()  # Convert to uppercase\n",
        "        cleaned_seq = cleaned_seq.replace(\"?\", \"\").replace(\".\", \"\")  # Remove unwanted characters\n",
        "\n",
        "        # ensure each sequence contains at least one valid nucleotide (A, C, G, T, N)\n",
        "        if any(c in \"ACGTN\" for c in cleaned_seq):\n",
        "            record.seq = cleaned_seq  # update the sequence\n",
        "            SeqIO.write(record, out_f, \"fasta\")\n",
        "        else:\n",
        "            print(f\"Warning: Removed empty or invalid sequence {record.id}\")\n",
        "\n",
        "print(f\" Cleaned alignment saved as: {output_file}\")\n",
        "\n",
        "sequences = list(SeqIO.parse(output_file, \"fasta\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPegM_dFLG1v"
      },
      "source": [
        "### Generating a Genetic Distance Matrix\n",
        "\n",
        "Generate the pairwise distance matrix, assuming the Tamura and Nei model for the evolutionary rate, which has two parameters allowing for different base frequencies and different transition and substitution rates. This function generates a matrix of pairwise distances between taxa. Visualise the resulting matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEzOGeXrLG1w"
      },
      "outputs": [],
      "source": [
        "# calculate pairwise distance matrix\n",
        "calculator = DistanceCalculator('identity')\n",
        "alignment = MultipleSeqAlignment(sequences)\n",
        "dmatrix = calculator.get_distance(alignment)\n",
        "\n",
        "# convert to a DataFrame\n",
        "dist_df = pd.DataFrame(dmatrix.matrix, index=dmatrix.names, columns=dmatrix.names)\n",
        "\n",
        "# plot the distance matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(dist_df, cmap='viridis_r', square=True)\n",
        "plt.title(\"Genetic Distance Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVYY6osjLG1w"
      },
      "source": [
        "### Construct an initial tree using the neighbour-joining algorithm\n",
        "\n",
        "We will first estimate the tree using the neighbour-joining approach and root the tree at the outgroup, accession number KJ642617, which was sampled in Nigeria in 1971."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyPMUQiOLG1w"
      },
      "outputs": [],
      "source": [
        "# construct a NJ tree\n",
        "constructor = DistanceTreeConstructor()\n",
        "nj_tree = constructor.nj(dmatrix)\n",
        "\n",
        "# convert to newick format for re-rooting\n",
        "newick_tree = EteTree(nj_tree.format('newick'), format=1)\n",
        "\n",
        "# identify the outgroup\n",
        "outgroup_label = next((leaf.name for leaf in newick_tree.iter_leaves() if re.search(r'REF', leaf.name, re.IGNORECASE)), None)\n",
        "\n",
        "# set the outgroup and root tree\n",
        "if outgroup_label:\n",
        "    newick_tree.set_outgroup(outgroup_label)\n",
        "    print(f\"Outgroup set to: {outgroup_label}\")\n",
        "else:\n",
        "    print(\"No matching outgroup found!\")\n",
        "\n",
        "newick_string = newick_tree.write(format=1)\n",
        "newick_io = io.StringIO(newick_string)\n",
        "\n",
        "rooted_tree = Phylo.read(newick_io, \"newick\")\n",
        "print(f\"Tree successfully re-rooted with {len(rooted_tree.get_terminals())} terminal nodes.\")\n",
        "\n",
        "# draw the tree\n",
        "fig, ax = plt.subplots(figsize=(12, 15))\n",
        "\n",
        "Phylo.draw(\n",
        "    rooted_tree,\n",
        "    axes=ax,\n",
        "    do_show=False,\n",
        "    branch_labels=None,\n",
        "    label_func=lambda clade: clade.name if clade.is_terminal() else None\n",
        ")\n",
        "\n",
        "# formatting\n",
        "plt.title(\"Rooted NJ Tree\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "# save and plot\n",
        "out_path = os.path.join(output_dir, 'rooted_nj_tree_mpxv.png')\n",
        "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
        "\n",
        "# also save tree as newick format\n",
        "tree_output_path = os.path.join(output_dir, 'rooted_nj_tree.tree')\n",
        "Phylo.write(rooted_tree, tree_output_path, \"newick\")\n",
        "\n",
        "plt.show()\n",
        "print(f\"Tree saved successfully at: {out_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgie4k0fLG1x"
      },
      "source": [
        "# Bayesian phylogenetic inference\n",
        "\n",
        "Now let's look at inferring the tree with a Bayesian approach, using the phylostan package (github.com/4ment/phylostan).\n",
        "\n",
        "The package uses pystan, but runs under the hood via the command line, so we just need to pass the relevant input files as arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwPwOgX-LG1y",
        "outputId": "f3e52f9e-aaeb-4534-9819-87a9dc7dd964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5781  100  5781    0     0  13218      0 --:--:-- --:--:-- --:--:-- 13228\n",
            " Running Phylostan with the following command:\n",
            "phylostan run -s MPXV-GTR-W4.stan -m HKY -C 4 --heterochronous --estimate_rate --clock strict --coalescent constant -i drive/MyDrive/StatML4PopHealth/practical7/mpxv/cleaned_alignment.fasta -t drive/MyDrive/StatML4PopHealth/practical7/mpxv/rooted_nj_tree.tree -o drive/MyDrive/StatML4PopHealth/practical7/mpxv/MPXV_output -q meanfield\n",
            " Running Phylostan...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7b68ad18f433>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Running Phylostan...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Phylostan Output:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## Uncomment this code chunk if you would like to run phylostan\n",
        "\n",
        "# # file paths\n",
        "# fasta = f\"{output_dir}/cleaned_alignment.fasta\"\n",
        "# tree = f\"{output_dir}/rooted_nj_tree.tree\"  # Input tree\n",
        "# # Get stan model\n",
        "# !curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/refs/heads/main/practicals/day5/practical7/MPXV-GTR-W4.stan\"\n",
        "# !curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/refs/heads/main/practicals/day5/practical7/MPXV-GTR-W4.pkl\"\n",
        "\n",
        "# stan_model = \"MPXV-GTR-W4.stan\"\n",
        "# output_prefix = f'{output_dir}/MPXV_output'  # Output file prefix\n",
        "# output_tree_path = f'{output_dir}/MPXV_output.trees'\n",
        "\n",
        "# command = [\n",
        "#     \"phylostan\", \"run\",\n",
        "#     \"-s\", stan_model,\n",
        "#     \"-m\", \"HKY\",\n",
        "#     \"-C\", \"4\",\n",
        "#     \"--heterochronous\",\n",
        "#     \"--estimate_rate\",\n",
        "#     \"--clock\", \"strict\",\n",
        "#     \"--coalescent\", \"constant\",\n",
        "#     \"-i\", fasta,  # Input sequence alignment\n",
        "#     \"-t\", tree,  # Input tree file\n",
        "#     \"-o\", output_prefix,  # Output prefix\n",
        "#     \"-q\", \"meanfield\"\n",
        "#     #\"-q\", \"mcmc\"  # Change from \"meanfield\" (variational inference) to \"mcmc\"\n",
        "# ]\n",
        "\n",
        "# print(\" Running Phylostan with the following command:\")\n",
        "# print(shlex.join(command))  # Formats the command as it would be executed in a shell\n",
        "\n",
        "# print(\" Running Phylostan...\")\n",
        "# try:\n",
        "#     result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "#     print(\" Phylostan Output:\\n\", result.stdout)\n",
        "# except subprocess.CalledProcessError as e:\n",
        "#     print(\" Phylostan Error Output:\\n\", e.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗The code chunk below downloads the pregenerated phylostan output. If you would like to run phylostan yourself, please comment out the code chunk below and uncomment the code chunk above. Please remember to install phylostan before running it. Beware, it may take a few hours to run."
      ],
      "metadata": {
        "id": "VUGScO9xpiHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment out this code chunk if you have run phylostan\n",
        "\n",
        "!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day5/practical7/MPXV_output\"\n",
        "!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day5/practical7/MPXV_output.trees\"\n",
        "\n",
        "output_prefix = \"MPXV_output\"\n",
        "output_tree_path = \"MPXV_output.trees\""
      ],
      "metadata": {
        "id": "jyvPg89qgoJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarise posterior\n",
        "\n",
        "We now summarise the posteriors of the estimated parameters."
      ],
      "metadata": {
        "id": "6jr6ogo8HXbK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKCxBJmbLG1z"
      },
      "outputs": [],
      "source": [
        "# tree height --> height\n",
        "# evolutionary rate --> rate\n",
        "# ratio of transition and transversion rates of HKY model --> kappa\n",
        "# population size --> theta\n",
        "\n",
        "po = az.from_cmdstan(posterior=output_prefix)\n",
        "\n",
        "# parameter names\n",
        "params_of_interest = [\"rate\", \"height\", \"theta\", \"kappa\"]\n",
        "\n",
        "# trace plots for each parameter\n",
        "for param in params_of_interest:\n",
        "    az.plot_trace(po, var_names=[param])\n",
        "    plt.suptitle(f\"Trace plot of {param}\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also plot the posterior alone\n",
        "# summarise posteriors|\n",
        "for param in params_of_interest:\n",
        "    az.plot_posterior(po, var_names=[param],hdi_prob=.95, round_to=3)\n",
        "    plt.title(f\"Posterior distribution of {param}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3Vr-JgMziph_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Maximum Clade Credibility tree\n",
        "\n",
        "We would like to visualise the posterior samples of the tree. We can find the maximum clade credibility tree and plot it, showing the branch lengths in units of calendar time and illustrating the TMRCA of all the sampled taxa.\n",
        "\n",
        "Comparing the TMRCA to that in Parker et al, we infer a much earlier emergence date of the outbreak. This illustrates the importance of including sufficient background sequences before attempting phylogenetic inference."
      ],
      "metadata": {
        "id": "scSfaPwdxrec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load posterior trees\n",
        "with open(output_tree_path) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# map taxa labels from posterior tree samples\n",
        "\n",
        "translate_block = []\n",
        "in_translate = False\n",
        "for line in lines:\n",
        "    if line.strip().lower().startswith(\"translate\"):\n",
        "        in_translate = True\n",
        "        continue\n",
        "    if in_translate:\n",
        "        if \";\" in line:\n",
        "            break\n",
        "        translate_block.append(line.strip())\n",
        "\n",
        "translate_dict = {}\n",
        "for line in translate_block:\n",
        "    match = re.match(r\"(\\d+)\\s+([^\\s,]+)\", line)\n",
        "    if match:\n",
        "        num, label = match.groups()\n",
        "        translate_dict[num] = label\n",
        "\n",
        "# read trees\n",
        "tree_lines = [line for line in lines if line.strip().startswith(\"tree \")]\n",
        "trees = []\n",
        "for line in tree_lines:\n",
        "    parts = line.split(\"=\", 1)\n",
        "    if len(parts) == 2:\n",
        "        newick_str = parts[1].strip().rstrip(\";\")\n",
        "        try:\n",
        "            tree = Phylo.read(io.StringIO(newick_str), \"newick\")\n",
        "            trees.append(tree)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "# find MCC tree\n",
        "def tree_topology_key(tree):\n",
        "    clades = [frozenset(leaf.name for leaf in clade.get_terminals()) for clade in tree.find_clades()]\n",
        "    return frozenset(clades)\n",
        "\n",
        "topology_counts = defaultdict(int)\n",
        "for tree in trees:\n",
        "    key = tree_topology_key(tree)\n",
        "    topology_counts[key] += 1\n",
        "\n",
        "most_common_topology = max(topology_counts.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "mcc_tree = None\n",
        "for tree in trees:\n",
        "    if tree_topology_key(tree) == most_common_topology:\n",
        "        mcc_tree = tree\n",
        "        break\n",
        "\n",
        "# relabel tips\n",
        "for term in mcc_tree.get_terminals():\n",
        "    if term.name in translate_dict:\n",
        "        term.name = translate_dict[term.name]\n",
        "\n",
        "# extract sampling dates\n",
        "def extract_sampling_date(name):\n",
        "    try:\n",
        "        return float(name.split(\"_\")[-1])\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "tip_dates = {term.name: extract_sampling_date(term.name) for term in mcc_tree.get_terminals()}\n",
        "valid_dates = [d for d in tip_dates.values() if d is not None]\n",
        "most_recent_year = max(valid_dates)\n",
        "tree_depth = max(mcc_tree.distance(term) for term in mcc_tree.get_terminals())\n",
        "\n",
        "# plot MCC tree with time-scaled x-axis\n",
        "fig = plt.figure(figsize=(14, 12))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "Phylo.draw(mcc_tree, axes=ax, do_show=False)\n",
        "\n",
        "xticks = ax.get_xticks()\n",
        "year_ticks = [round(most_recent_year - (tree_depth - x), 2) for x in xticks]\n",
        "ax.set_xticks(xticks)\n",
        "ax.set_xticklabels(year_ticks)\n",
        "ax.set_xlabel(\"Calendar Year\")\n",
        "ax.set_title(\"MCC Tree\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xiROo-2wwkoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "phylolab2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}