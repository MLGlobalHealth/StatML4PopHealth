{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMXhj0pRx83J"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/imperial.png\" width=\"250\" vspace=\"8\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/mlgh.png\" width=\"220\" hspace=\"50\" vspace=\"5\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/ammi.png\" width=\"190\"/>\n",
        "\n",
        "<font size=\"6\">Modern Statistics and Machine Learning <br>for Population Health in Africa </font>\n",
        "\n",
        "<font size=\"4\">24th - 28th March 2025</font>\n",
        "\n",
        "</center>\n",
        "\n",
        "# Compartmental Models in Stan\n",
        "### Ettie Unwin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cifBIPk-x-Zu"
      },
      "source": [
        "The first part of this tutorial is based on a paper by [Ginsztajn et al.](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.9164). This work is licensed under a [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://creativecommons.org/licenses/by-nc-nd/4.0/).\n",
        "\n",
        "In this tutorial, we demonstrate how to formulate, fit, and diagnose compartmental model like the ones we considered this morning in Stan using the [cmdstanpy](https://mc-stan.org/cmdstanpy/) interface. (See yesterday's notes for why we are interested in using Stan). We consider two different types of routinely collected data to fit our models to: prevalence data (number / proportion of infected people in a population) and incidence data (newly infected people in a population).\n",
        "\n",
        "In this example, we examine an outbreak of influenza A (H1N1) in 1978 at a British boarding school. The data consists of the daily number of students in bed (prevalence data), spanning over a time interval of 14 days. There were 763 male students who were mostly full boarders and 512 of them became ill. The outbreak lasted from the 22nd of January to the 4th of February. It is reported that one infected boy started the epidemic, which spread rapidly in the relatively closed community of the boarding school. The data are freely available in the R package outbreaks, maintained as part of the [R Epidemics Consortium](http://www.repidemicsconsortium.org/), and is a great resource for trying to fit different models yourself after the course. This is only available as an R package so we have saved the data as a .json file to use for this practical. Since there was no publicly available incidence data associated with this outbreak, we provide some simulated data created to mimic the behaviour of the outbreak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv_yXxszlP9P"
      },
      "source": [
        "## Install cmdstanpy\n",
        "Like the other practicals, we will start by install cmdstanpy for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzRZGRColP9P"
      },
      "outputs": [],
      "source": [
        "!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/scripts/utilities.py\"\n",
        "\n",
        "from utilities import custom_install_cmdstan, test_cmdstan_installation\n",
        "\n",
        "custom_install_cmdstan()\n",
        "\n",
        "# if we want to test the installation, we can run the bernoulli hello world example\n",
        "test_cmdstan_installation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_El0rWoFnCCX"
      },
      "source": [
        "## Exploring the data\n",
        "\n",
        "First we will load in all the images and data that we will need for this practical.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spc7dAQRCy4x"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "resource_urls= [\n",
        "    # data\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/data/flu_data.csv\",\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/data/incidence.csv\",\n",
        "    # # Stan models\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/stan_models/seir_incidence.stan\",\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/stan_models/seir_prevalence.stan\",\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/stan_models/sir_model.stan\",\n",
        "    \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/stan_models/sir_model_prior.stan\"\n",
        "     ]\n",
        "\n",
        "# Note this will overwrite existing files, remove -O if that is not desired\n",
        "for url in resource_urls:\n",
        "   subprocess.run([\"curl\", \"-O\", url], check=True)\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b8-QOjjUhCb"
      },
      "outputs": [],
      "source": [
        "!cat seir_incidence.stan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubLuw2dmUdE3"
      },
      "source": [
        "!cat seir_incidence.stan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcA-wv8BDOdK"
      },
      "source": [
        "Now we can use these files.  The first one we will explore is the flu data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvkW-KQuoKsO"
      },
      "outputs": [],
      "source": [
        "# Load in the data using pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('flu_data.csv')\n",
        "\n",
        "# Convert the dates to datetime format\n",
        "df.Date = pd.to_datetime(df.date)\n",
        "\n",
        "# Use date as index\n",
        "df = df.set_index(\"date\")\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnARYkwIpup_"
      },
      "source": [
        "From this we can see that we have a two week timeseries, as expected, with dates, numbers of students in bed and the number who are convalescing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky1_H6RqJ2q"
      },
      "source": [
        "Q1) Make a plot of the timeseries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn9xB-UlqQXm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Number of children')\n",
        "ax1.plot(df.in_bed, color = 'tab:red', linewidth= 1, label = 'In bed')\n",
        "ax1.plot(df.convalescent, color = 'tab:blue', linewidth= 1, label = \"Convalescent\")\n",
        "ax1.set_facecolor('white')\n",
        "ax1.legend(loc = \"upper right\")\n",
        "ax1.tick_params(axis='x', labelrotation=90)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hog0edWc1KkS"
      },
      "source": [
        "## Fitting an SIR (transmission) model to prevalence data\n",
        "The simplest model we can consider is the Susceptible-Infected-Recovered (SIR) model. This splits the population in three time-dependent compartments: the susceptible ($S$), the infected (and infectious) ($I$), and the recovered (and not infectious) compartments ($R$). When a susceptible individual comes into contact with an infectious individual, the former can become infected for some time, and then recover and become immune.  \n",
        "\n",
        "<img src=\" https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/images/sir.png\">\n",
        "\n",
        "From Figure 1, the rate of progression between the S and I compartments is $\\beta * I / N$ where $\\beta$ is the contact rate, $I$ is the number of infected people and $N$ is the total population. The rate of progression between the $I$ and $R$ compartments is $\\sigma$ the recovery rate or 1 divided by the duration of infection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhcePbNh7Bcl"
      },
      "source": [
        "\n",
        "Q2) Define the equations for an SIR model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-kY61jxlP9S"
      },
      "source": [
        "$$\\frac{dS}{dt} = -\\beta \\frac{I}{N} S$$\n",
        "$$\\frac{dI}{dt} = \\beta \\frac{I}{N} - \\sigma I $$\n",
        "$$\\frac{dR}{dt} = \\sigma I $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayTWB3yD7DrM"
      },
      "source": [
        "\n",
        "Q3) What are the assumptions of this model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoPSYZbjlP9S"
      },
      "source": [
        "- homogeneous mixing\n",
        "- no births or deaths\n",
        "- permanent immunity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q8-moH2BWI4"
      },
      "source": [
        "## Defining the statistical model\n",
        "We now define the statistical inference model that we will use to fit our tranmission model to data. Here we introduce the likelihood or sampling distribution for our model\n",
        "$$p(y|\\theta),$$\n",
        "which tells us, given model parameters $\\theta$, how to generate data $y$. In a Bayesian framework, the set of plausible values is characterised by the posterior distribution,\n",
        "$$\n",
        "p(\\theta | y).\n",
        "$$\n",
        "\n",
        "Bayes’ rule teaches us that\n",
        "$$\n",
        "p(\\theta | y) \\sim p(y | \\theta) p(\\theta)\n",
        "$$\n",
        "where $p(\\theta | y)$ is our posterior distribution and this is proportional to $p(y|\\theta)$ our likelihood multiplied by $p(θ)$ our prior distribution. The prior encodes information or our belief about the parameters we have before observing the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQuoGhlC4BJ"
      },
      "source": [
        "### The likelihood\n",
        "This is the part of the model that we used to link the model estimates of the number of infected students, $I_{ODE}(t)$, for given parameters ($\\beta$ and $\\sigma$) to the observed data, i.e the number of students in bed, $I_{obs}(t)$. We choose to model the number of students in bed with a count distribution – the Negative Binomial. This distribution allows us to use $I_{ODE}(t)$ as the expected value and account for over-dispersion, through the parameter $\\phi$:\n",
        "$$\n",
        "I_{obs}(t)∼NegBin(I_{ODE}(t), \\phi)\n",
        "$$\n",
        "Therefore our likelihood is $p(y∣\\theta)$, with $\\theta = (\\beta, \\sigma, \\phi)$ as the parameters of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gbs6ppjDJoa"
      },
      "source": [
        "### Priors\n",
        "We need to specify a prior for each of our three parameter $\\theta = (\\beta, \\sigma, \\phi)$. One advantage of the Bayesian approach is that we can formally incorporate prior knowledge about the parameters into the model. We can change this prior if more information becomes available, constraining our parameter estimation more tightly or, on the contrary, increasing its variance. Choosing priors is one of the tricky parts of Bayesian modelling but comes with practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-pQnikRDMEV"
      },
      "source": [
        "### Predictions and derived quantities\n",
        "Once we fit the model and obtain a posterior distribution for $\\theta$, we can derive additional quantities of interests. The posterior distribution of predictions:\n",
        "$$\n",
        "p(y_{pred}∣y)=\\int p(y_{pred}|\\theta) p(\\theta | y)d\\theta.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr3LH21BDns3"
      },
      "source": [
        "## Coding the model in Stan\n",
        "\n",
        "We will need to import the following packages to fit the compartmental model in Stan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Q1iNXoG808"
      },
      "outputs": [],
      "source": [
        "# Load packages used in this installation\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import urllib.request\n",
        "\n",
        "from cmdstanpy import CmdStanModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWi7Uov0yeZO"
      },
      "source": [
        "Now we need to install CmdStanPy.\n",
        "\n",
        "Step 1: install CmdStanPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3NawsIwGRjo"
      },
      "source": [
        "### Coding the ODE\n",
        "An ODE takes the form\n",
        "$$\n",
        "\\frac{dz}{dt}=f(t,z)\n",
        "$$\n",
        "where $z$ are the states of the compartmental model ($z=(S,I,R)$ for our first example) and $t$ is time. We also need to provide initial conditions $z_0$ at $t_0$ and the times, $τ$, at which we evaluate the solution.\n",
        "\n",
        "To specify an ODE in Stan, we first code $f$ in the functions block. This function must observe a strict signature:\n",
        "\n",
        "```python\n",
        "vector f(real time, vector state, ...)\n",
        "```\n",
        "\n",
        "where\n",
        "\n",
        "* time, $t$;\n",
        "* state, the different compartment, $z$;\n",
        "* ..., optional arguments for the different parameters in the model.\n",
        "\n",
        "In our example, the ODEs for the SIR model is defined with the following structure.\n",
        "\n",
        "```python\n",
        "functions {\n",
        "  vector sir(real t,\n",
        "             vector y,\n",
        "             real beta,\n",
        "             real sigma,\n",
        "             real N) {\n",
        "\n",
        "      vector[3] dydt;\n",
        "\n",
        "      real S = y[1];\n",
        "      real I = y[2];\n",
        "      real R = y[3];\n",
        "      \n",
        "      dydt[1] =  S equation;\n",
        "      dydt[2] =  I equation;\n",
        "      dydt[3] =  R equation;\n",
        "      \n",
        "      return dydt;\n",
        "  }\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsBtA5gSIVec"
      },
      "source": [
        "Q4) Fill in the equations for the differential equations for S, I and R:\n",
        "\n",
        "```python\n",
        "functions {\n",
        "  vector sir(real t,\n",
        "             vector y,\n",
        "             real beta,\n",
        "             real sigma,\n",
        "             real N) {\n",
        "\n",
        "      vector[3] dydt;\n",
        "\n",
        "      real S = y[1];\n",
        "      real I = y[2];\n",
        "      real R = y[3];\n",
        "\n",
        "      dydt[1] =  fill in here;\n",
        "      dydt[2] =  fill in here;\n",
        "      dydt[3] =  fill in here;\n",
        "\n",
        "      return dydt;\n",
        "  }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wxJ3EJfJL0q"
      },
      "source": [
        "We evaluate the solution numerically by using one of Stan’s numerical integrators.  Here we choose the Runge-Kutta 4th / 5th order and a call to the integrator looks as follows:\n",
        "\n",
        "```python\n",
        "y = ode_rk45(sir, y0, t0, t, beta, sigma, N);;\n",
        "```\n",
        "where\n",
        "\n",
        "* sir, the name of the function that returns the derivatives that we wrote earlier;\n",
        "* y0, the initial condition;\n",
        "* t0, the time of the initial condition;\n",
        "* t, the times at which we require the solution to be evaluated;\n",
        "* beta, the transmission parameter;\n",
        "* sigma, the recovery rate;\n",
        "* N, the number of people in our population.\n",
        "\n",
        "We now have all the ingredients to solve our ODE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QDQQZbgKBJd"
      },
      "source": [
        "### Building the model\n",
        "We next code the model in Stan, working through the following coding blocks.\n",
        "\n",
        "A) We first need the function block from above that specifies the SIR model.  \n",
        "\n",
        "B) Fixed data is declared in the data block.  This is things like the initial conditions, times and number of days.\n",
        "```python\n",
        "data {\n",
        "  int n_days;\n",
        "  vector[3] y0;\n",
        "  real t0;\n",
        "  array[n_days] real t;\n",
        "  int N;\n",
        "  array[n_days] int cases;\n",
        "}\n",
        "```\n",
        "\n",
        "C) We next declare the model parameters. If you want some parameter to be bounded, and it is not already guaranteed by it's prior, you need to specify <lower=a, upper=b> when declaring this parameter. Note that this is how you put a truncated prior distribution on a parameter and here we choose to define a prior on the inverse of $\\phi$.  \n",
        "```python\n",
        "parameters {\n",
        "  real<lower=0> sigma;\n",
        "  real<lower=0> beta;\n",
        "  real<lower=0> phi_inv;\n",
        "}\n",
        "```\n",
        "\n",
        "D) And then transforms of the parameters\n",
        "```python\n",
        "transformed parameters{\n",
        "  real y[n_days, 3];\n",
        "  real phi = 1. / phi_inv;\n",
        "  \n",
        "  y = integrate_ode_rk45(sir, y0, t0, t, beta, sigma, N);\n",
        "}\n",
        "```\n",
        "\n",
        "E) Our model consists of the prior and likelihood as described above. Here we assume some priors for our parameters and define our likelihood.\n",
        "```python\n",
        "model {\n",
        "  //priors\n",
        "  beta ~ normal(4, 2); //truncated at 0\n",
        "  sigma ~ normal(0.8, 0.3); //truncated at 0\n",
        "  phi_inv ~ exponential(5);\n",
        "  \n",
        "  //likelihood\n",
        "  cases ~ neg_binomial_2(y[:, 2], phi);\n",
        "}\n",
        "```\n",
        "\n",
        "F) Finally untangled from the inference, we predict the number of cases, basic reproduction number and recovery time in the generated quantities block:\n",
        "\n",
        "```python\n",
        "generated quantities {\n",
        "  real R0 = beta / sigma;\n",
        "  real recovery_time = 1 / sigma;\n",
        "\n",
        "  array[n_days] real pred_cases;\n",
        "  pred_cases = neg_binomial_2_rng(y[:,2], phi);\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa8ggLAOL00n"
      },
      "source": [
        "### Fitting the model in python\n",
        "\n",
        "Here we write the code to fit the model in python to the number of children in bed.  You need to copy all the model parts (functions, data, parameters, transformed parameters, model and generated quantities) from the above section into a file called  ```sir_model.stan``` in a directory called ```stan_models```.\n",
        "\n",
        "Next we create the data struture to fit our model to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWwnT_izM3ic"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set the population size\n",
        "N = 763\n",
        "\n",
        "# Define initial conditions\n",
        "i0 = 1\n",
        "s0 = N - i0\n",
        "r0 = 0\n",
        "y0 = [s0, i0, r0]\n",
        "\n",
        "# Make the data struture\n",
        "stan_data = {\n",
        "    \"n_days\": len(df.in_bed),\n",
        "    \"y0\": y0,\n",
        "    \"t0\": 0,\n",
        "    \"t\": np.arange(1, len(df.in_bed)+1),\n",
        "    \"N\": N,\n",
        "    \"cases\": df.in_bed\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYMdmdtTPRRa"
      },
      "source": [
        "Then we compile our stan model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqKb10CyOyx3"
      },
      "outputs": [],
      "source": [
        "sir_model = CmdStanModel(stan_file = 'sir_model.stan')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLgs2IimPvCP"
      },
      "source": [
        "Finally we run MCMC. For this problem, it suffices to use Stan’s defaults. Note that, as is standard practice, we run 4 Markov chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHbjd0GYO0xj"
      },
      "outputs": [],
      "source": [
        "fit_sir_model = sir_model.sample(data = stan_data,\n",
        "                                 iter_sampling = 2000,\n",
        "                                 chains = 4,\n",
        "                                 seed = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYweuirShck"
      },
      "source": [
        "We notice this prints lots of debugging statements to the display. This can be limited by the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ImTG9pySp6v"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "cmdstanpy_logger = logging.getLogger(\"cmdstanpy\")\n",
        "cmdstanpy_logger.disabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSZIw7TxSwvp"
      },
      "outputs": [],
      "source": [
        "fit_sir_model = sir_model.sample(data = stan_data,\n",
        "                                 iter_sampling = 2000,\n",
        "                                 chains = 4,\n",
        "                                 seed = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ST8H9NTRI3"
      },
      "source": [
        "## Checking the model\n",
        "\n",
        "When developing a model it is good to check the model is performing as you expect it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxsvnC0jUEGf"
      },
      "source": [
        "### Inference\n",
        "A good place to start is with a summary table of the results, which displays the posterior mean, standard error, quantiles, and some useful diagnostics. Since there are lots of parmeters in the model we will consider 'beta', 'sigma' and 'recovery time' only here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wx-RzTgUFRU"
      },
      "outputs": [],
      "source": [
        "sir_summary = fit_sir_model.summary()\n",
        "sir_summary.filter(items=(\"sigma\", \"beta\", \"recovery_time\"), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX8sGJ63Zebp"
      },
      "source": [
        "Stan gives us lots of information to evaluate whether the inference is reliable:\n",
        "\n",
        "* During sampling, warnings can tell us if something is wrong (here we have no warnings but you should check yours).\n",
        "* In the summary table, several quantities are available to check inference.\n",
        "  - Here we note that $\\hat R$ is close to 1 (< 1.001), indicating the 4 Markov chains are in close agreement with one another.\n",
        "  - The effective samples size, ESS_bulk and ESS_tail, are large, which means the Markov chains were able to cohesively explore the parameter space.\n",
        "  - Conversely, large $\\hat{R}$ and low effective sample size would indicate that the Markov chains are poorly mixing.\n",
        "  \n",
        "Apart from fixing coding errors, improving the mixing of the Markov chains almost always requires tweaking the model specification, for example with a reparameterisation or stronger priors.\n",
        "\n",
        "We can use the arivz package to  plot the marginal posterior densities for each chain, which enables us to confirm the Markov chains are in agreement with one another, and the trace plots to explore how well our chains have mixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HZliWXMZ9pn"
      },
      "outputs": [],
      "source": [
        "import arviz as az\n",
        "\n",
        "az.style.use(\"arviz-doc\")\n",
        "az.plot_trace(fit_sir_model,\n",
        "              var_names = [\"beta\", \"sigma\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ggevcreVqn"
      },
      "source": [
        "### Model\n",
        "Now that we trust our inference, we can check the utility of our model. Utility is problem specific and can include the precise estimation of a quantity or predicting future behaviors. In general, it is good to check if our model, once fitted, produces simulations that are consistent with the observed data. This is the idea behind posterior predictive checks.\n",
        "\n",
        "We sample predictions, $y_{pred}$, from $p(y_{pred}∣y)$ and use these samples to construct a fitted curve for students in bed, together with the uncertainty (90% interval, meaning observed data is expected to fall outside of this interval one in ten times). This posterior predictive check allows us to verify if the model captures the structure of the data. Here we see that the model gives a satisfying fit to the data, and that the model uncertainty is able to capture the variation of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPV1YITpfN2_"
      },
      "outputs": [],
      "source": [
        "post_pred = pd.DataFrame(sir_summary.filter(like=\"pred_cases\", axis=0))\n",
        "post_pred[\"t\"] = range(1, 15)\n",
        "post_pred[\"cases\"] = list(df.in_bed)\n",
        "\n",
        "post_pred = post_pred.set_index(\"t\")\n",
        "post_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ms9cCGzhWWP"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Number of children in bed')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.scatter(x = post_pred.index, y = post_pred.cases, color = 'tab:red', label = \"Cases\")\n",
        "ax1.plot(post_pred.Mean, color = 'tab:blue', linewidth= 1, label = \"Mean estimated cases\")\n",
        "ax1.fill_between(x = post_pred.index,  y1 = post_pred['5%'], y2 = post_pred['95%'], alpha=0.2)\n",
        "ax1.set_facecolor('white')\n",
        "ax1.legend(loc = \"upper right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iROGxzdanhWj"
      },
      "outputs": [],
      "source": [
        "infected = sir_summary.filter(items=(\"y[1,2]\", \"y[2,2]\", \"y[3,2]\", \"y[4,2]\", \"y[5,2]\",\n",
        "                                     \"y[6,2]\", \"y[7,2]\", \"y[8,2]\", \"y[9,2]\", \"y[10,2]\",\n",
        "                                     \"y[11,2]\", \"y[12,2]\", \"y[13,2]\", \"y[14,2]\",), axis=0)\n",
        "\n",
        "infected[\"t\"] = range(1, 15)\n",
        "infected = infected.set_index(\"t\")\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Number of infected children')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.plot(infected.Mean, color = 'tab:blue', linewidth= 1, label = \"Mean estimated number of infected\")\n",
        "ax1.fill_between(x = infected.index,  y1 = infected['5%'], y2 = infected['95%'], alpha=0.2)\n",
        "ax1.set_facecolor('white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8veuCDBorBp"
      },
      "source": [
        "### Priors\n",
        "We can check if our priors are sound by computing the a priori probability of various epidemiological parameters of interest. For instance for influenza, we know that the recovery time is approximately 1 week. We want priors that allow for every reasonable configurations of the data but exclude absurd scenarios, per our domain expertise. To check if our priors fulfill this role, we can do a prior predictive check.\n",
        "\n",
        "To conduct a prior predictive check, we take the same model as before, put the parameters of interest in the generated_quantities code block, and remove the likelihood term from the model. Without the likelihood, the parameters are not fitted to the data and are thus sampled from their prior distribution. The Stan code is thus the same as the final Stan code, without the ```cases ~ neg_binomial_2(y[:,2], phi);``` line.\n",
        "\n",
        "We can now compile the model without the likelihood term.  \n",
        "\n",
        "* You need to create a new model file called ```sir_model_prior.stan``` by removing the likelihood term from your model and saving it in your drive.\n",
        "* You also need to change ``` pred_cases = neg_binomial_2_rng(y[:, 2], phi);``` to ``` pred_cases = neg_binomial_2_rng(y[:, 2] + 1e-5, phi);``` to ensure all your values are defined.\n",
        "\n",
        "The following code will mount your drive to this notebook and load in the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksIv1r_mqsBE"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#stan_file_prior = 'drive/MyDrive/sir_model_prior.stan'\n",
        "sir_model_prior = CmdStanModel(stan_file = 'sir_model_prior.stan')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gmm29tfquGz"
      },
      "source": [
        "\n",
        "Then we can sample from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPn3F37_5fFq"
      },
      "outputs": [],
      "source": [
        "prior_check = sir_model_prior.sample(data = stan_data,\n",
        "                                     iter_sampling = 2000,\n",
        "                                     chains = 4,\n",
        "                                     seed = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdpLYaPu5msK"
      },
      "source": [
        "This gives us samples from the a priori distribution of parameters, which we can visualize. Here we show the distribution of the log of the recovery time, with the red bars showing loose bounds on the recovery time (1/2 day and 30 days). We observe that most of the probability mass is between the red bars but we still allow more extreme values, meaning our posterior can concentrate outside the bars, if the data warrants it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAQtLMBb6q7V"
      },
      "outputs": [],
      "source": [
        "recovery_time = prior_check.stan_variable(\"recovery_time\")\n",
        "ax = pd.DataFrame(recovery_time).plot(kind='density', logx=True)\n",
        "ax.axvline(x=0.5)\n",
        "ax.axvline(x=30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAOPgqs_57xv"
      },
      "source": [
        "We thus see that these distributions are coherent with domain knowledge. See [here](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations) for more recommendations on prior choice.\n",
        "\n",
        "We can also plot trajectories of infection according to the prior, that is the number of infected people at each time according to prior distributions of parameters. The dashed red line shows the total population of children.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toTOPVj3J7wi"
      },
      "outputs": [],
      "source": [
        "infection_draws = prior_check.draws_pd(\"y\")\n",
        "lines = plt.plot(range(1,15),\n",
        "                 infection_draws.iloc[:, [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]].T,\n",
        "                 color = \"k\", alpha = 0.1)\n",
        "plt.axhline(y=763, color='r', linestyle='--')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Number of infected children')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maTRLpeN6Tyv"
      },
      "source": [
        "And the median (blue line) and 90% interval of the a priori number of student in bed (i.e the observed number of infected students)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6fk8TeklP9X"
      },
      "outputs": [],
      "source": [
        "prior_pred_cases = pd.DataFrame(prior_check.summary().filter(like=\"pred_cases\", axis=0))\n",
        "prior_pred_cases[\"t\"] = range(1, 15)\n",
        "prior_pred_cases = prior_pred_cases.set_index(\"t\")\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Number of children in bed')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.plot(prior_pred_cases.Mean, color = 'tab:blue', linewidth= 1, label = \"Mean estimated cases\")\n",
        "ax1.fill_between(x = prior_pred_cases.index,  y1 = prior_pred_cases['5%'], y2 = prior_pred_cases['95%'], alpha=0.2)\n",
        "ax1.set_facecolor('white')\n",
        "ax1.legend(loc = \"center right\")\n",
        "ax1.axhline(y=763, color='r', linestyle='--')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EnvMubn6a6P"
      },
      "source": [
        "It seems that most trajectories are reasonable and quite diverse. Still, some of the curves look a little bit funky and suggest we could refine our priors and make them more informative, although it may not be needed here.\n",
        "\n",
        "Typically, we can get away with priors that do not capture all our a priori knowledge, provided the data is informative enough. However when dealing with complicated models and relatively sparse data, we usually need well constructed priors to regularize our estimates and avoid non-identifiability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kt40EelP9X"
      },
      "source": [
        "## Fitting an SEIR model to prevalence data\n",
        "\n",
        "A person who is infected with flu is not immediately infectious so it makes sense to include an \"Exposed\" compartment in our model. This should improve the fit to our model (although we don't evaluate that here in this practical).\n",
        "\n",
        "<img src=\" https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/day4/practical5/images/seir.png\">\n",
        "\n",
        "The notation in Figure 2 is similar to the SIR model but we have a new parameter $\\gamma$ which is the rate of progression from the exposed to infected compartment.  It is equal to 1 divided by the incubation period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bkw4Q6TlP9Y"
      },
      "source": [
        "Q4) What are the equations for an SEIR model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htnvg4LflP9Y"
      },
      "source": [
        "$$\\frac{dS}{dt} = -\\beta \\frac{I}{N} S$$\n",
        "$$\\frac{dE}{dt} = \\beta \\frac{I}{N} - \\gamma E $$\n",
        "$$\\frac{dI}{dt} = \\gamma E - \\sigma I $$\n",
        "$$\\frac{dR}{dt} = \\sigma I $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojDll4-clP9Y"
      },
      "source": [
        "Q5) Edit the stan model file to turn the SIR model in an SEIR model. Save this in the ```stan_model``` directory under a new file called ```seir_prevalence.stan```.  Since we have a new parameter in our model $\\gamma$ we need to define a prior for this.  From the literature the incubation period for flu is around 2 days so a prior for gamma of $N(0.5, 0.25)$ would be suitable.  \n",
        "\n",
        "Hint:  You will need to change the following parts of the model.\n",
        "\n",
        "- The functions block to encode the new ODE model,\n",
        "- The data block so that y0 has dimensions of 4,\n",
        "- The parameter block so the gamma parameter is added,\n",
        "- The model block needs the prior for gamma adding and,\n",
        "- The generated quantity block can be used to calculate the incubation period (1/gamma).\n",
        "\n",
        "Similar to before, the SEIR model can be run as follows. Note we also need to add an initial condition for our exposed compartment.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BEb9ETflP9Y"
      },
      "outputs": [],
      "source": [
        "# Set the population size\n",
        "N = 763\n",
        "\n",
        "# Define initial conditions\n",
        "i0 = 1\n",
        "e0 = 0\n",
        "s0 = N - i0\n",
        "r0 = 0\n",
        "y0 = [s0, e0, i0, r0]\n",
        "\n",
        "# Make the data struture\n",
        "seir_data = {\n",
        "    \"n_days\": len(df.in_bed),\n",
        "    \"y0\": y0,\n",
        "    \"t0\": 0,\n",
        "    \"t\": np.arange(1, len(df.in_bed)+1),\n",
        "    \"N\": N,\n",
        "    \"cases\": df.in_bed\n",
        "}\n",
        "\n",
        "seir_model = CmdStanModel(stan_file = 'seir_prevalence.stan')\n",
        "\n",
        "fit_seir_model = seir_model.sample(data = seir_data,\n",
        "                                   iter_sampling = 2000,\n",
        "                                   chains = 4,\n",
        "                                   seed = 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6sNrfS4lP9Y"
      },
      "source": [
        "Q6) Print a summary for your results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlcXNHBMlP9Y"
      },
      "outputs": [],
      "source": [
        "seir_summary = fit_seir_model.summary()\n",
        "seir_summary.filter(items=(\"sigma\", \"beta\", \"recovery_time\", \"gamma\", \"incubation_period\"), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVIi1dxUlP9Y"
      },
      "source": [
        "Q7) Produce plots for our sample predictions of the number of students in bed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-nL-BjNlP9Y"
      },
      "outputs": [],
      "source": [
        "post_pred = pd.DataFrame(seir_summary.filter(like=\"pred_cases\", axis=0))\n",
        "post_pred[\"t\"] = range(1, 15)\n",
        "post_pred[\"cases\"] = list(df.in_bed)\n",
        "\n",
        "post_pred = post_pred.set_index(\"t\")\n",
        "post_pred\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Number of children in bed')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.scatter(x = post_pred.index, y = post_pred.cases, color = 'tab:red', label = \"Cases\")\n",
        "ax1.plot(post_pred.Mean, color = 'tab:blue', linewidth= 1, label = \"Mean estimated cases\")\n",
        "ax1.fill_between(x = post_pred.index,  y1 = post_pred['5%'], y2 = post_pred['95%'], alpha=0.2)\n",
        "ax1.set_facecolor('white')\n",
        "ax1.legend(loc = \"upper right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF12KdQmlP9Y"
      },
      "source": [
        "## Fitting an SEIR model to incidence data\n",
        "\n",
        "The number of infected people in a population is not the only type of data collected during an outbreak. Often we get a line list or a list of the times at which people were infected (or showed symptoms). We have simulated some incidence data for a flu like outbreak with similar parameters to the school data and this can be found in the file ```incidence_seir.csv```. (Do speak to one of us if you are interested in how we did this!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4H5T5I9lP9Y"
      },
      "outputs": [],
      "source": [
        "# Read in incidence data\n",
        "\n",
        "# Load in the data using pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('incidence.csv')\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3s9PJVolP9Y"
      },
      "source": [
        "We now need to change our model to fit the incidence from our model to the data rather than the prevalence. First we need to calculate the incidence, which is equal to the number of people leaving the exposed compartment at each time step.  \n",
        "\n",
        "Q8) Make a new copy of our SEIR model by re-saving ```seir_prevalence.stan``` as ```seir_incidence.stan```. The incidence can be calculated by first adding an ODE for cumumlative incidence in the functions block.\n",
        "\n",
        "```python\n",
        "dydt[5] = gamma * E\n",
        "```\n",
        "Remember you will need to change the dimensions of dydt, the output of solving your differential equations y and create a new initial condition.  Then you will need to create a for loop that calculates incidence.\n",
        "\n",
        "```python\n",
        "incidence[1] = y[1, 5] - 0\n",
        "for (i in 2:n_days)\n",
        "  incidence[i] = y[i, 5] - y[i-1, 5];\n",
        "```\n",
        "\n",
        "Then we need to update the likelihood in the model block to the following since we are now saying that our incidence is negatively binomially distributed instead of the total number of cases.\n",
        "```python\n",
        "//sampling distribution\n",
        "cases ~ neg_binomial_2(incidence, phi);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTa4ZKWtlP9Y"
      },
      "source": [
        "Q9) Use similar code to before to fit our model and print a summary of our parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYq-T41VlP9Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set the population size\n",
        "N = 763\n",
        "\n",
        "# Define initial conditions\n",
        "i0 = 1\n",
        "e0 = 0\n",
        "s0 = N - i0\n",
        "r0 = 0\n",
        "c0 = 0\n",
        "y0 = [s0, e0, i0, r0, c0]\n",
        "\n",
        "# Make the data struture\n",
        "seir_data = {\n",
        "    \"n_days\": len(df.x),\n",
        "    \"y0\": y0,\n",
        "    \"t0\": 0,\n",
        "    \"t\": np.arange(1, len(df.x)+1),\n",
        "    \"N\": N,\n",
        "    \"cases\": df.x\n",
        "}\n",
        "\n",
        "seir_incidence_model = CmdStanModel(stan_file = 'seir_incidence.stan')\n",
        "\n",
        "fit_seir_incidence_model = seir_incidence_model.sample(data = seir_data,\n",
        "                                                       iter_sampling = 2000,\n",
        "                                                       chains = 4,\n",
        "                                                       seed = 0)\n",
        "\n",
        "seir_incidence_summary = fit_seir_incidence_model.summary()\n",
        "seir_incidence_summary.filter(items=(\"sigma\", \"beta\", \"recovery_time\", \"gamma\", \"incubation_period\"), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYCertw2l921"
      },
      "source": [
        "Q10) Plot your data and model fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYcQt_A6lP9Z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "post_pred = pd.DataFrame(seir_incidence_summary.filter(like=\"pred_incidence\", axis=0))\n",
        "post_pred[\"t\"] = range(1, 14)\n",
        "post_pred[\"incidence\"] = list(df.x)\n",
        "\n",
        "post_pred = post_pred.set_index(\"t\")\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.grid(True, which='both', color = 'k', alpha = 0.1)\n",
        "ax1.set_ylabel('Incidence')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.scatter(x = post_pred.index, y = post_pred.incidence, color = 'tab:red', label = \"Incidence\")\n",
        "ax1.plot(post_pred.Mean, color = 'tab:blue', linewidth= 1, label = \"Mean estimated incidence\")\n",
        "ax1.fill_between(x = post_pred.index,  y1 = post_pred['5%'], y2 = post_pred['95%'], alpha=0.2)\n",
        "ax1.set_facecolor('white')\n",
        "ax1.legend(loc = \"upper right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tujNQLoMaYTw"
      },
      "source": [
        "Q11) Explore what impact changing your priors has on the model fit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-puBqAlP9Z"
      },
      "source": [
        "## Extension material\n",
        "\n",
        "Now you have fit simple SIR and SEIR model to some data based on influenser, we will consider using all the material you have learned today to design and fit a compartmental model of Ebola to the line list incidence data found in the supplementary material of [Garske (2017)](https://royalsocietypublishing.org/doi/10.1098/rstb.2016.0308).\n",
        "\n",
        "Suggested workflow:\n",
        "\n",
        "1) Download and investigate the [data](https://royalsocietypublishing.org/action/downloadSupplement?doi=10.1098%2Frstb.2016.0308&file=rstb20160308supp1.csv)\n",
        "\n",
        "2) Do a quick literature review about how Ebola is spread.  A few good resources: [Drake et al. (2015)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4517740/), [WHO fact sheet](https://www.who.int/news-room/fact-sheets/detail/ebola-virus-disease) and [Nash et al. (2024)](https://www.thelancet.com/article/S1473-3099(24)00374-8/abstract).\n",
        "\n",
        "3) Design a flow chart for Ebola transmission using pen and paper.\n",
        "\n",
        "4) Write the equations for this model.\n",
        "\n",
        "5) Code them using python and stan.\n",
        "\n",
        "6) Investigate what priors make sense."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
