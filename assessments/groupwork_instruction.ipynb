{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHnWn8ZmFubpgdwBgT84Sh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/MLGlobalHealth/StatML4PopHealth/blob/main/assessments/groupwork_instruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"ytDYVDOeXso6"}},{"cell_type":"markdown","source":["<center>\n","<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/imperial.png\" width=\"250\" vspace=\"8\"/>\n","<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/mlgh.png\" width=\"220\" hspace=\"50\" vspace=\"5\"/>\n","<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/ammi.png\" width=\"190\"/>\n","\n","<font size=\"6\">Modern Statistics and Machine Learning<br> for Population Health in Africa </font>\n","\n","<font size=\"4\">24th - 28th March 2025</font>\n","\n","</center>"],"metadata":{"id":"FkHOP7nRffVX"}},{"cell_type":"markdown","source":["## Data\n","\n","Today we are going to consider an air pollution data set for eight cities in seven African countries, Lagos, Accra, Nairobi, Yaounde, Bujumbura, Kisumu, Kampala, and Gulu. [Especially, fine particulate matter (PM2.5) of 2.5 microns or less in diameter are linked to poor health outcomes and millions of premature deaths globally](https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(24)00003-2/fulltext). [In the UK, PM2.5 emissions have decreased by $>85\\%$ since 1970](https://www.gov.uk/government/statistics/emissions-of-air-pollutants/emissions-of-air-pollutants-in-the-uk-particulate-matter-pm10-and-pm25), but in many other parts of the world PM2.5 emissions have increased to extremely dangerous levels.\n","\n","PM2.5 are most accurately measured through low-cost on-the-ground sensor networks, but these are expensive. [We will focus on predicting PM2.5 concentrations using satellite-derived PM2.5 data that are themselves derived from Aerosol Optical Depth (AOD) measurements of the Sentinel 5P satellite instrument, available through the Google Earth Data Catalogue.](https://developers.google.com/earth-engine/datasets/catalog/sentinel-5p)\n","\n","In fact, many different atmospheric variables are measured and can be used as features to predict PM2.5 concentrations to empower communities to access crucial air quality information, provide them with the evidence needed to tackle local pollution challenges, and improve public health. The data that we consider today were previously used as part of a [prediction challenge](https://zindi.africa/competitions/airqo-african-air-quality-prediction-challenge/data) to support the [Clean Africa Air network](https://www.airqo.net).\n","\n","For our purposes today, we will only use the noisy satellite-based PM2.5 measurements to predict actual, daily average PM2.5 concentrations using GP methodology. We will also focus on a single location to simplify matters. Our main objective is to estimate the number of days in a full year that PM2.5 concentrations were unhealthy above 35 Î¼g/m3, [posing a significant risk to the general population as per WHO guidelines](https://www.who.int/publications/i/item/9789240034228)."],"metadata":{"id":"ZA45HGbntVGS"}},{"cell_type":"code","source":["# Install CmdStanPy for Google Colab\n","!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/scripts/utilities.py\"\n","from utilities import custom_install_cmdstan, test_cmdstan_installation\n","custom_install_cmdstan()"],"metadata":{"id":"Z1ygSALHtmIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pickle\n","from pathlib import Path\n","\n","import arviz as az\n","from cmdstanpy import CmdStanModel\n","import numpy as np\n","import pandas as pd\n","import folium\n","from datetime import timedelta,datetime\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","\n","# Aesthetics\n","sns.set_theme(style=\"whitegrid\")\n","font = {\"family\": \"sans-serif\",\n","        \"weight\": \"normal\",\n","\t\t\"size\": 10.5}\n","mpl.rc('font', **font)"],"metadata":{"id":"d1IRDGOxt4am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","output_dir = Path(*[\"drive\", \"MyDrive\", \"short_course\", \"output\"])\n","output_dir.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"sJJFUR2muUP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the input data\n","!curl -O \"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/data/sentinel_5p_particulate_matter.csv\""],"metadata":{"id":"xSx5mSZoSg_G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Select and explore PM2.5 data\n","\n","Let us load and have a look at the satellite-based data of atmospheric variables in the eight cities:\n"],"metadata":{"id":"QWiySp6bu_K2"}},{"cell_type":"code","source":["# put WHO classification of PM2_5 health risks into table\n","dwho = {\n","    'risk': ['good','moderate','unhealthy for sensitive groups','unhealthy','very unhealthy'],\n","    'pm25_low': [0, 10, 25, 35, 55],\n","    'pm25_high': [10, 25, 35, 55,1000],\n","    'text': ['good air quality',\n","             'acceptable for short-term exposure but may affect sensitive groups over long-term exposure',\n","             'increased risk for vulnerable populations such as children, elderly, and people with pre-existing health conditions',\n","             'significant risk to the general population, especially with prolonged exposure',\n","             'severe health risk to the general public']\n","}\n","dwho = pd.DataFrame(dwho)\n","dwho"],"metadata":{"id":"SE0pf3dqvpoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load data\n","db = pd.read_csv(\"sentinel_5p_particulate_matter.csv\")\n","db.head()"],"metadata":{"id":"My42OaVQyc_s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is very rich data. We will subset this to Kampala, the capital of Uganda with about 7 million people in the wider metropolitan area. The name Kampala goes back to the hill of the impala, a particular anthilope species that were once grazing there in large numbers. Let us plot the locations for which atmospheric variables are available:"],"metadata":{"id":"IHr2m8kNzWhc"}},{"cell_type":"code","source":["#\tsubset to Kampala, Uganda\n","dp_kampala = db.loc[db['city'] == \"Kampala\",['city', 'country', 'date', 'hour', 'site_id', 'site_latitude', 'site_longitude', 'pm2_5']]\n","dp_kampala['date'] = pd.to_datetime(dp_kampala['date'], format = '%Y-%m-%d')\n","dp_kampala['year'] = dp_kampala['date'].dt.strftime('%Y')\n","dp_kampala['month'] = dp_kampala['date'].dt.strftime('%m')\n","dp_kampala.head()\n"],"metadata":{"id":"_nD1KMqIznaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# name sites and merge\n","dp_sites = dp_kampala.loc[:,['city', 'site_id','site_latitude', 'site_longitude']].drop_duplicates()\n","dp_sites['site_name'] = ['site-' + str(i) for i in range(1,len(dp_sites)+1)]\n","dp_kampala = pd.merge(dp_kampala, dp_sites, on = ['city','site_id','site_latitude', 'site_longitude'])\n","dp_kampala.head()"],"metadata":{"id":"iPigNe-61CY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a map showing measurement locations in Kampala\n","# coordinates for the center of Kampala\n","lat_kampala = 0.3136\n","lon_kampala = 32.5818\n","\n","# create map\n","map = folium.Map(location=[lat_kampala, lon_kampala], zoom_start=12)\n","\n","# Add markers for each site\n","for idx, row in dp_sites.iterrows():\n","    folium.Marker(\n","        location=[row['site_latitude'], row['site_longitude']],\n","        popup=row['site_name']\n","    ).add_to(map)\n","\n","# Sace and display  the map\n","map.save(output_dir.joinpath(\"kampala_map.html\"))\n","map"],"metadata":{"id":"U3_JnMPG3EcM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us plot the time series of the noisy PM2.5 measurements in two sites:"],"metadata":{"id":"uGlfxt7F7Vim"}},{"cell_type":"code","source":["# Select specific sites and rename them\n","dp = dp_kampala[dp_kampala['site_name'].isin(['site-4', 'site-9'])]\n","dp.loc[:,['site_name']] = dp['site_name'].replace({'site-4': 'Buwate', 'site-9': 'Kyebando'})\n","dp"],"metadata":{"id":"yFoU83opzKUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","custom_palette = sns.color_palette([\"#073344FF\", \"#0B7C9AFF\"])\n","\n","# Create a rectangle for the WHO PM2.5 range\n","for _, row in dwho.iterrows():\n","    plt.fill_between(\n","        [dp['date'].min() - timedelta(days=10), dp['date'].max() + timedelta(days=10)],\n","        row['pm25_low'], row['pm25_high'],\n","        color=sns.color_palette(\"OrRd\", len(dwho))[_], alpha=0.5, label=row['risk']\n","    )\n","# Plot PM2.5 data points\n","sns.scatterplot(\n","    data=dp, x='date', y='pm2_5', hue='site_name', palette=custom_palette, s=50\n",")\n","\n","# Customizing the plot\n","plt.xlim([dp['date'].min() - timedelta(days=10), dp['date'].max() + timedelta(days=10)])\n","plt.ylim([0, max(dp['pm2_5']) * 1.05])\n","plt.xlabel('')\n","plt.ylabel('PM2.5 concentration')\n","plt.title('PM2.5 Measurements in Kampala')\n","plt.legend(title='Location')"],"metadata":{"id":"AS8XSczn7VEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Non-parametric modelling with GPs\n","\n","Let us denote by $y_i$ the PM2.5 concentrations in the $i$th observation.\n","\n","We model $y_i$ with\n","\\begin{align*}\n","& y_i \\sim \\text{LogNormal}(\\mu_i, \\sigma^2) \\\\\n","& \\mu_i = \\beta_0 + f(\\text{date}_i) \\\\\n","& \\beta_0 \\sim \\text{Normal}(0, 2) \\\\\n","& f \\sim \\text{GP}(0,k) \\\\\n","\\end{align*}\n","where the median is $\\exp(\\mu_i)$, the mean is $\\exp(\\mu_i + \\sigma^2/2)$, the variance is\n","$(\\exp(\\sigma^2)-1)exp(2\\mu_i + \\sigma^2)$, and $f$ is a random function that is\n","evaluated using dates as inputs and so captures time effects non-parametrically. The random function is given a zero-mean GP prior with squared exponential kernel with GP variance $\\alpha$ and lengthscale $\\rho$.\n","We specify hyper-priors by\n","\\begin{align*}\n","& \\alpha \\sim \\text{Half-Cauchy}(0, 1) \\\\\n","& \\rho \\sim \\text{Inv-Gamma}(5, 1) \\\\\n","& \\sigma \\sim \\text{Half-Cauchy}(0,1)\n","\\end{align*}\n","The hyperparameters $\\alpha$, $\\rho$ are given default priors that are suitable for a standardised input domain $[0,1]$.\n","\n","Below is the `Stan` model file, [based on the Stan v2.36.0 manual](https://mc-stan.org/docs/stan-users-guide/gaussian-processes.html#predictive-inference-with-a-gaussian-process).\n","\n","Note how the variance to mean ratio in the LogNormal scales exponentially with $\\sigma^2$, and for this reason\n","one typically attaches priors with relatively limited variance to the baseline parameter when compared\n","to other observation likelihood models.\n","\n","Note that the joint distribution of $f$ evaluated at a finite set of inputs is just a multivariate normal, and so we can straightforwardly generate samples from $f$ through linear transformation of iid standard normal random variables (through the line $f = L_f * z$)."],"metadata":{"id":"7uG5NBwCBePS"}},{"cell_type":"markdown","source":["## Group Project Instructions\n","\n","### Objective\n","The goal of this group project is to analyze air pollution data from a selected site using a Gaussian Process (GP) model with Hilbert Space approximation. The primary objective is to estimate the number of days in a year that PM2.5 concentrations were at unhealthy level (above 35 $\\mu$g/$m^3$).\n","\n","-----\n","### Tasks\n","\n","#### 1. Site Selection\n","Select **one site** from Kampala city. Make sure that there are not too many missing values.\n","\n","#### 2. Model Implementation\n","Implement the **Gaussian Process (GP) model** as specified in the previous section, using **Hilbert Space approximation**. You can also consider changing kernel from squared exponential to, for example, matern class kernel (Optional).  \n","\n","#### 3. Model Diagnostics\n","Evaluate **convergence and mixing** of the Markov Chain Monte Carlo (MCMC) algorithm.  \n","- Obtain summary statistics, including **Rhat** and **Effective sample size (ESS)**.\n","- Since there may be many parameters, focus on the **trace plot of the model parameter with the lowest effective sample size**.\n","- Note there may be a few divergent transitions, but for the purpose of this project, you may proceed to next steps if they are deemed satisfactory.\n","\n","#### 4. Visualization\n","- Plot the **posterior median of the target variable (PM2.5 concentration)** over time.\n","- Include 95% credible intervals to visualize variability.\n","\n","#### 5. Answer the Main Objective\n","- Calculate the number of days in a full year that the level of PM2.5 concentrations were unhealthy above $35 \\mu g / m^3$.\n","- Summarize your findings and interpret the results in the context of public health.\n","\n","\n","### 6. Additional Sites (Optional)\n","- If time permits, **repeat the analysis for a few additional sites**.\n","- Compare the results across sites and discuss any spatial patterns or variability.\n","\n","-----\n","\n","### Deliverables\n","Prepare a short presentation with slides highlighting tasks achieved, with a focus on the results and conclusions of your analysis. Each group member should present for at least 2-3 minutes to ensure balanced participation. Submit your python notebook, one per group. Marks are available for achieving the different tasks in 1-6 (group mark), and contents and delivery of the presentation (individual mark)."],"metadata":{"id":"_qJahC_mOM4y"}},{"cell_type":"markdown","source":["### Tips / Hints\n","\n","* To select a site that is a good fit for the project, it's useful to plot all time series. Try following code\n","```\n","fig = px.line(dp_all,  x='date', y='pm2_5', color='site_name')\n","fig.show()\n","```\n","Choose a location where the first and last observations are more than 1 year apart, and not too many missing values in between. Use **all** observations available in the model fitting phase.\n","* You will have to obtain GP predictions on the days where the response variable (MP2.5 level) is not recorded.\n","* You can use `log_normal`, `lognormal_rng` functions to specify log normal likelihood or sample from log normal distribution. You can also see [Stan manual](`https://mc-stan.org/docs/2_21/functions-reference/lognormal.html`)."],"metadata":{"id":"3vvG6n2TZkP7"}},{"cell_type":"code","source":["fig = px.line(dp_all,  x='date', y='pm2_5', color='site_name')\n","fig.show()"],"metadata":{"id":"aDSUlXBcnOtz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will show data processing step below. In this example, we focus on 'site-9'\n"],"metadata":{"id":"1kx2smJxZkZ5"}},{"cell_type":"code","source":["dp = dp_kampala[dp_kampala['site_name'] == 'site-9'].sort_values(by=['date'])\n","print('The number of observation:', len(dp),'between', (dp['date'].min()).strftime('%d %B, %Y') , 'and', (dp['date'].max()).strftime('%d %B, %Y'))"],"metadata":{"id":"LFF59j3_-0Ir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["At the selected site, we have 229 observations during the period of 402 days\n","(from 21 January, 2023 to 26 February, 2024). We fit the GP model to these 229 points, and make prediction on the rest of the days (173 days). This can be done in `generated quantities` block"],"metadata":{"id":"BU1SxZaI_U_-"}},{"cell_type":"markdown","source":["Let's prepare the data. We want to standardize the variable $t$, which represents the date. Let $k_i$ denote the unstandardized day variable, ranging from 1 to 402 in this example.\n","\n","To standardize $t$, it is common practice to use only the observed (training) data when calculating the mean ($m$) and standard deviation ($s$). This means that in the standardized variable, given by $t_i = (k_i - m ) / s$, $m$ and $s$ are calculated exclusively from the observed data, ensuring that the standardization process does not incorporate any information from the validation or test sets."],"metadata":{"id":"27h_SBXx-ant"}},{"cell_type":"code","source":["# converting the date to start from 1\n","day_num = (dp.date - min(dp.date)).dt.days + 1.0\n","# get mean and standard diviation\n","mean_day = day_num.mean()\n","std_day = day_num.std()"],"metadata":{"id":"OUeNucnoG7YS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's use this in `dp`"],"metadata":{"id":"uTNeHTLqRVfC"}},{"cell_type":"code","source":["dp.loc[:,['day']] = day_num\n","dp.loc[:,['day_std']] = (dp['day'] - mean_day) / std_day"],"metadata":{"id":"WMbuhIqMP4X8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can create a new DataFrame to include the remaining days that are not present in the `dp` DataFrame."],"metadata":{"id":"aTTQjhpEPCi5"}},{"cell_type":"code","source":["# create df with all dates (converted date, which we call day)\n","dp_all ={\n","    'date' : [dp.date.min() + timedelta(days=x) for x in range((dp.date.max()-dp.date.min()).days + 1)],\n","    'day' : range(1, (dp.date.max()-dp.date.min()).days + 2),\n","}\n","dp_all = pd.DataFrame(dp_all)\n","# standardise `day` using mean and srandard diviation we calculated in the previous step\n","dp_all['day_std'] = (dp_all['day'] - mean_day) / std_day\n","# datafrmame for days without observation\n","dp_new = dp_all[~dp_all['day'].isin(day_num)].sort_values(by=['date'])"],"metadata":{"id":"WvjjTRJFPAGt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then we have all data we need to provide to `Stan` model, but we will create a dataframe which combine both data."],"metadata":{"id":"04cZrKBBSPkv"}},{"cell_type":"code","source":["dp.loc[:,['source']] = 'obs'\n","dp_new.loc[:,['source']] = 'pred'\n","dp_all = pd.concat([dp[['pm2_5','date','day','day_std','source']], dp_new], axis=0).sort_values(by=['date'])"],"metadata":{"id":"55VbkaE9SPAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","\n","# Create a rectangle for the WHO PM2.5 range\n","for _, row in dwho.iterrows():\n","    plt.fill_between(\n","        [dp['date'].min() - timedelta(days=10), dp['date'].max() + timedelta(days=10)],\n","        row['pm25_low'], row['pm25_high'],\n","        color=sns.color_palette(\"OrRd\", len(dwho))[_], alpha=0.5, label=row['risk']\n","    )\n","# Plot PM2.5 data points\n","sns.scatterplot(\n","    data= dp_all, x='date', y='pm2_5', s=50, color = \"#0B7C9AFF\"\n",")\n","# Customizing the plot\n","plt.xlim([dp['date'].min() - timedelta(days=10), dp['date'].max() + timedelta(days=10)])\n","plt.ylim([0, max(dp['pm2_5']) * 1.05])\n","plt.xlabel('')\n","plt.ylabel('PM2.5 concentration')\n","plt.title('PM2.5 Measurements in Kampala')"],"metadata":{"id":"HkXYQnEea9ez"},"execution_count":null,"outputs":[]}]}